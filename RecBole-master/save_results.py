#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script ƒë·ªÉ l∆∞u k·∫øt qu·∫£ metrics v√† th·ªùi gian ch·∫°y t·ª´ RecBole v√†o file result.txt
"""

import os
import json
import time
from datetime import datetime
from recbole.quick_start import run

def save_results_to_file(result_dict, config_dict, output_file="result.txt"):
    """
    L∆∞u k·∫øt qu·∫£ metrics v√† th√¥ng tin hu·∫•n luy·ªán v√†o file
    
    Args:
        result_dict: Dictionary ch·ª©a k·∫øt qu·∫£ t·ª´ RecBole
        config_dict: Dictionary ch·ª©a c·∫•u h√¨nh
        output_file: T√™n file output
    """
    
    # T·∫°o th√¥ng tin header
    header = "=" * 80 + "\n"
    header += f"RECBOLE TRAINING RESULTS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    header += "=" * 80 + "\n\n"
    
    # Th√¥ng tin c·∫•u h√¨nh
    config_info = "CONFIGURATION:\n"
    config_info += "-" * 40 + "\n"
    for key, value in config_dict.items():
        config_info += f"{key}: {value}\n"
    config_info += "\n"
    
    # K·∫øt qu·∫£ validation t·ªët nh·∫•t
    best_valid_info = "BEST VALIDATION RESULTS:\n"
    best_valid_info += "-" * 40 + "\n"
    best_valid_info += f"Best Valid Score: {result_dict['best_valid_score']:.4f}\n"
    best_valid_info += "Best Valid Metrics:\n"
    for metric, value in result_dict['best_valid_result'].items():
        best_valid_info += f"  {metric}: {value:.4f}\n"
    best_valid_info += "\n"
    
    # K·∫øt qu·∫£ test
    test_info = "TEST RESULTS:\n"
    test_info += "-" * 40 + "\n"
    for metric, value in result_dict['test_result'].items():
        test_info += f"{metric}: {value:.4f}\n"
    test_info += "\n"
    
    # Th√¥ng tin b·ªï sung
    additional_info = "ADDITIONAL INFORMATION:\n"
    additional_info += "-" * 40 + "\n"
    additional_info += f"Valid Score Bigger is Better: {result_dict['valid_score_bigger']}\n"
    additional_info += f"Output File: {output_file}\n"
    additional_info += f"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    
    # G·ªôp t·∫•t c·∫£ th√¥ng tin
    full_content = header + config_info + best_valid_info + test_info + additional_info
    
    # Ghi v√†o file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(full_content)
    
    print(f"‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o file: {output_file}")
    print(f"üìä Best Valid Score: {result_dict['best_valid_score']:.4f}")
    print(f"üß™ Test AUC: {result_dict['test_result'].get('AUC', 'N/A')}")
    print(f"üß™ Test LogLoss: {result_dict['test_result'].get('LogLoss', 'N/A')}")

def run_with_result_saving(model, dataset, config_file_list=None, config_dict=None, output_file="result.txt"):
    """
    Ch·∫°y RecBole v√† t·ª± ƒë·ªông l∆∞u k·∫øt qu·∫£ v√†o file
    
    Args:
        model: T√™n model
        dataset: T√™n dataset  
        config_file_list: Danh s√°ch file config
        config_dict: Dictionary c·∫•u h√¨nh
        output_file: T√™n file output
    """
    
    print(f"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán model {model} tr√™n dataset {dataset}")
    print(f"üìù K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o: {output_file}")
    
    # Ghi l·∫°i th·ªùi gian b·∫Øt ƒë·∫ßu
    start_time = time.time()
    
    # Ch·∫°y RecBole
    result = run(
        model=model,
        dataset=dataset,
        config_file_list=config_file_list,
        config_dict=config_dict
    )
    
    # Ghi l·∫°i th·ªùi gian k·∫øt th√∫c
    end_time = time.time()
    total_time = end_time - start_time
    
    # Th√™m th√¥ng tin th·ªùi gian v√†o config_dict
    if config_dict is None:
        config_dict = {}
    
    config_dict.update({
        'model': model,
        'dataset': dataset,
        'total_training_time': f"{total_time:.2f} seconds",
        'total_training_time_minutes': f"{total_time/60:.2f} minutes",
        'start_time': datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S'),
        'end_time': datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')
    })
    
    # L∆∞u k·∫øt qu·∫£ v√†o file
    save_results_to_file(result, config_dict, output_file)
    
    return result

if __name__ == "__main__":
    # V√≠ d·ª• s·ª≠ d·ª•ng
    config_dict = {
        "epochs": 20,
        "learning_rate": 0.001,
        "eval_type": "both",
        "metrics": ["AUC", "LogLoss"],
        "save_result": True,
        "save_log": True,
        "show_progress": True,
    }
    
    result = run_with_result_saving(
        model="NFM",
        dataset="ml-100k", 
        config_dict=config_dict,
        output_file="result.txt"
    )

